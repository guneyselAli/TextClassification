{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"rec.autos\", \"sci.electronics\",\"talk.politics.misc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test_data = fetch_20newsgroups(subset='test',categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer\n",
    "def vectorizer_func(X_train,X_test):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf Vectorizer\n",
    "def tfidf_func(X_train,X_test):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train = tfidf.fit_transform(X_train)\n",
    "    X_test = tfidf.transform(X_test)\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "def word2vec_func(X_train, X_test):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "        return \" \".join(filtered_tokens)\n",
    "\n",
    "    X_train = [preprocess_text(doc).split() for doc in X_train]\n",
    "    X_test = [preprocess_text(doc).split() for doc in X_test]\n",
    "    word2vec_model = Word2Vec(X_train, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "    def vectorize(sentence,w2v_model):\n",
    "        words_vecs = [w2v_model.wv[word] for word in sentence\n",
    "                    if word in w2v_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis = 0)\n",
    "\n",
    "    X_train = np.array([vectorize(sentence,word2vec_model) for sentence in X_train])\n",
    "    X_test = np.array([vectorize(sentence,word2vec_model) for sentence in X_test])\n",
    "    \n",
    "    scaler = MinMaxScaler() #MultinomialNB doesn't accept negative values. Therefore scaling has been applied.\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test= scaler.fit_transform(X_test)\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doc2Vec\n",
    "def doc2vec_func(X_train, X_test):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "        return \" \".join(filtered_tokens)\n",
    "\n",
    "    X_train = [preprocess_text(doc).split() for doc in X_train]\n",
    "    X_test = [preprocess_text(doc).split() for doc in X_test]\n",
    "    tagged_X_train = [TaggedDocument(doc, tags=[str(i)]) for i, doc in enumerate(X_train)]\n",
    "\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=1, dm=1, epochs=20)\n",
    "    model.build_vocab(tagged_X_train)\n",
    "    model.train(tagged_X_train, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    X_train = [model.infer_vector(doc) for doc in X_train] \n",
    "    X_test = [model.infer_vector(doc) for doc in X_test]\n",
    "    \n",
    "    scaler = MinMaxScaler() #MultinomialNB doesn't accept negative values. Therefore scaling has been applied.\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test= scaler.fit_transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [(\"Count_Vectorizer\",vectorizer_func),\n",
    "                 (\"Tf-Idf\",tfidf_func), \n",
    "                 (\"Word2Vec\", word2vec_func), \n",
    "                 (\"Doc2Vec\",doc2vec_func)]\n",
    "\n",
    "methods_X_values = []\n",
    "for method in methods:\n",
    "    func = method[1]\n",
    "    X_train, X_test = func(train_data.data, test_data.data)\n",
    "    methods_X_values.append([method[0],X_train,X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "dt =  DecisionTreeClassifier()\n",
    "\n",
    "classifiers = [('MultinomialNB', nb),\n",
    "               ('LogisticRegression', lr),\n",
    "               ('SVC', svc),\n",
    "               ('DecisionTree',dt)]\n",
    "grid_nb = {'alpha':[0.1, 1.0, 2.0], 'fit_prior':[True,False]}\n",
    "grid_lr = {'penalty':['l2'], 'C':[0.01, 0.1, 1.0, 10.0], 'max_iter' :[999999]}\n",
    "grid_svc = {'C':[0.1, 1.0, 10],'degree': [2, 3, 4]}\n",
    "grid_dt = {'max_depth':[2,5,10,20,None], 'max_features':['sqrt',None]}\n",
    "param_grids = {'MultinomialNB':grid_nb, 'LogisticRegression':grid_lr,\n",
    "               'SVC':grid_svc, 'DecisionTree':grid_dt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(index = [i[0] for i in methods],columns = [i[0] for i in classifiers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%6.25 Completed\n",
      "%12.5 Completed\n",
      "%18.75 Completed\n",
      "%25.0 Completed\n",
      "%31.25 Completed\n",
      "%37.5 Completed\n",
      "%43.75 Completed\n",
      "%50.0 Completed\n",
      "%56.25 Completed\n",
      "%62.5 Completed\n",
      "%68.75 Completed\n",
      "%75.0 Completed\n",
      "%81.25 Completed\n",
      "%87.5 Completed\n",
      "%93.75 Completed\n",
      "%100.0 Completed\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total_len = len(methods_X_values) * len(classifiers)\n",
    "for X_values in methods_X_values:\n",
    "    for classifier in classifiers:\n",
    "        grid_cv = GridSearchCV(classifier[1],param_grid = param_grids[classifier[0]])\n",
    "        grid_cv.fit(X_values[1],train_data.target)\n",
    "        #classifier[1].fit(X_values[1],train_data.target)\n",
    "        #predictions = classifier[1].predict(X_values[2])\n",
    "        predictions = grid_cv.predict(X_values[2])\n",
    "        accuracy = accuracy_score(test_data.target, predictions)\n",
    "        scores_df.at[X_values[0], classifier[0]] = accuracy\n",
    "        i+=1\n",
    "        print(f\"%{100*i/total_len} Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count_Vectorizer</th>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.902639</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tf-Idf</th>\n",
       "      <td>0.957234</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.929026</td>\n",
       "      <td>0.731574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec</th>\n",
       "      <td>0.406733</td>\n",
       "      <td>0.435851</td>\n",
       "      <td>0.466788</td>\n",
       "      <td>0.424932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2Vec</th>\n",
       "      <td>0.898999</td>\n",
       "      <td>0.833485</td>\n",
       "      <td>0.864422</td>\n",
       "      <td>0.590537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MultinomialNB LogisticRegression       SVC DecisionTree\n",
       "Count_Vectorizer      0.961783           0.902639  0.878981     0.770701\n",
       "Tf-Idf                0.957234           0.942675  0.929026     0.731574\n",
       "Word2Vec              0.406733           0.435851  0.466788     0.424932\n",
       "Doc2Vec               0.898999           0.833485  0.864422     0.590537"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
